{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ed0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote_plus\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import urllib\n",
    "import uuid\n",
    "\n",
    "def make_file(place, file_name, shoes_name,price, category, url):\n",
    "    f = open(place+\"/\"+file_name+\".txt\", 'w')\n",
    "    f.write(\"이름  : {}\\n\".format(shoes_name))\n",
    "    f.write(\"price : {}원\\n\".format(price))\n",
    "    f.write(\"category : {}\\n\".format(category))\n",
    "    f.write(\"url : {}\".format(url))\n",
    "    f.close()\n",
    "    pass \n",
    "\n",
    "def make_soup(url):\n",
    "    headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def max_price(price_list):\n",
    "    max_price =price_list[0]\n",
    "    for price in price_list :\n",
    "        if max_price < price :\n",
    "            max_price = price\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43494a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_place = \"zappos/Heel\"\n",
    "#os.mkdir(text_place)\n",
    "#os.mkdir(img_place)\n",
    "#category = 'platform_shoes'\n",
    "k = 5898\n",
    "for i in range(15,30): # 7page까지 완료 (04/04/21:47)\n",
    "    print(f\"{i}번째 크롤링 시작!\")\n",
    "    first_url = f'https://www.zappos.com/women-heels/CK_XARC41wGqAQEDwAEB4gIEAQIYFQ.zso?p={i}'\n",
    "    first_soup = make_soup(first_url)\n",
    "    first_log = first_soup.select('a.Kz-z')\n",
    "    for j in range(len(first_log)):\n",
    "        time.sleep(2)\n",
    "        second_url = 'https://www.zappos.com/'+first_log[j].get(\"href\")\n",
    "        second_soup = make_soup(second_url)\n",
    "        second_log = second_soup.select('ul.LL-z>li>a')\n",
    "        view_list = [\"Pair View\", \"Top View\", \"Left View\", \"Front View\", \"Right View\"]\n",
    "        for log in range(len(second_log)-1):\n",
    "            category = second_log[log].select('img')[0].get('alt')\n",
    "            if category in view_list : \n",
    "                img_list = second_log[log].get('href')\n",
    "                urllib.request.urlretrieve(img_list, img_place +'/' + category +'/' + category +\"_Mid_Heel\"+ \"_{}.jpg\".format(k))\n",
    "                k += 1\n",
    "    print(f\"{i}번 째 크롤링 끝, 다음 크롤링 진행 \")\n",
    "print(\"크롤링 끝\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
